# Fine-tuning Qwen3-0.6b on Chinese Grammaticality Judgement
This project studies the ability of grammatical judgement of lightweight multilingual language models (LLMs) in Chinese. Using the Chinese Grammatical Error Diagnosis (CGED) dataset, we construct 41,490 minimal sentence pairs, each consisting of an ungrammatical sentence and its correct version. We evaluate three small causal LLMs—XGLM-564M, BLOOM-560M, and Qwen3-0.6B—by comparing the log-probabilities they assign to each sentence in the pair. Results show that BLOOM and XGLM outperform Qwen in terms of overall accuracy as well as particular error categories like word order and missing words. We then fine-tune Qwen3-0.6B using a margin-based loss and Low-Rank Adaptation (LoRA), achieving a 9.43 percentage point gain in accuracy  (from 78.69% to 88.12%) on the test set. Sentence-length analysis further reveals that fine-tuning significantly reduces the performance gap on short sentences. Our results show that minimal-pair evaluation and lightweight fine-tuning are effective ways to improve the grammatical skills of Chinese language models.
