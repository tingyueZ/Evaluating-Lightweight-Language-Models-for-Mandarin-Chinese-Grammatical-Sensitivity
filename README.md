# Evaluating Lightweight Language Models for Mandarin Chinese Grammatical Sensitivity

This project evaluates three lightweight pre-trained multilingual causal language models—XGLM-564M, BLOOM-560M, and Qwen3-0.6B—on their ability to detect grammatical errors. We construct a large number of  different sentence pairs from the Chinese Grammatical Error Diagnosis (CGED) dataset, each containing a grammatically correct and its ungrammatical version, along with its corresponding error types. The models are expected to assign higher log probabilities to grammatical sentences. The last section presents an analysis of the performance of the evaluated language models based on overall accuracy and accuracy by specific error types. Our results show that (1) BLOOM-560M performs the best overall; (2) all three models perform well on basic grammatical errors like redundancy, but struggle with more complex structures like word order and missing elements; (3) small-scale models can also capture aspects of Chinese grammar and are worth considering for practical applications.
