{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sJVkeWgbrnt"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahLFQgoM3JCf",
        "outputId": "3aca9584-66c1-472c-9f24-a485aef3131f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Created 41490 sentence pairs from original data.\n",
            "({'sentence': '那下次见吧。', 'label': 1}, {'sentence': '那下次见面吧。', 'label': -1}) ({'sentence': '虽然我不能去但是他们都去。', 'label': 1}, {'sentence': '虽然我不能去但是别人他们都去。', 'label': -1}) ({'sentence': '他们都有很好的一天。', 'label': 1}, {'sentence': '他们都有很好的天。', 'label': -1})\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Mount Google Drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/data_cged/training_data.jsonl'\n",
        "\n",
        "# Load the data and create pairs directly\n",
        "def load_data_and_create_pairs(file_path):\n",
        "    sentence_pairs = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            item = json.loads(line.strip())\n",
        "            # Check if both correct and error fields are present and not empty\n",
        "            if item.get(\"correct\") and item.get(\"error\"):\n",
        "                correct_item = {\"sentence\": item[\"correct\"]}\n",
        "                ungrammatical_item = {\"sentence\": item[\"text\"]}\n",
        "                sentence_pairs.append((correct_item, ungrammatical_item))\n",
        "\n",
        "    return sentence_pairs\n",
        "\n",
        "sentence_pairs = load_data_and_create_pairs(file_path)\n",
        "\n",
        "print(f\"Created {len(sentence_pairs)} sentence pairs from original data.\")\n",
        "print(sentence_pairs[1], sentence_pairs[5], sentence_pairs[10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 80-10-10 split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_pairs, temp_pairs = train_test_split(sentence_pairs, test_size=0.2, random_state=42)\n",
        "val_pairs, test_pairs = train_test_split(temp_pairs, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Number of pairs in training set: {len(train_pairs)}\")\n",
        "print(f\"Number of pairs in validation set: {len(val_pairs)}\")\n",
        "print(f\"Number of pairs in test set: {len(test_pairs)}\")\n",
        "\n",
        "# Inspect a few pairs from each set\n",
        "print(\"\\nExamples from training set:\")\n",
        "print(train_pairs[:2])\n",
        "\n",
        "print(\"\\nExamples from validation set:\")\n",
        "print(val_pairs[:2])\n",
        "\n",
        "print(\"\\nExamples from test set:\")\n",
        "print(test_pairs[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EPulGFCmhiG",
        "outputId": "a905dd39-950d-48e1-8d11-912754d30f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pairs in training set: 33192\n",
            "Number of pairs in validation set: 4149\n",
            "Number of pairs in test set: 4149\n",
            "\n",
            "Examples from training set:\n",
            "[({'sentence': '吸烟包括吸烟者自己对吸烟者旁边的人有影响，比如说：癌症、记忆力衰弱等等。', 'label': 1}, {'sentence': '吸烟包括吸烟者自己对吸烟者旁边的人起影响，比如说：发癌症、记忆力衰弱等等。', 'label': -1}), ({'sentence': '包括我家、大城市里的一般的家庭开冰箱满是吃的东西。看马路的垃圾堆，有很多吃不下的东西。', 'label': 1}, {'sentence': '包括我家、大城市里的一般的家庭开冰箱满着吃的东西。看马路的拉圾所，有很多吃不下的东西。', 'label': -1})]\n",
            "\n",
            "Examples from validation set:\n",
            "[({'sentence': '请你帮我买一个电脑。', 'label': 1}, {'sentence': '请你对我买一个电脑。', 'label': -1}), ({'sentence': '他毕业于上海交通大学，今年二十三岁。他以前是记者，现在没有工作。', 'label': 1}, {'sentence': '他已经毕业于上海交通大学，他今年二十三岁。他以前是记者，现在是没有工作。', 'label': -1})]\n",
            "\n",
            "Examples from test set:\n",
            "[({'sentence': '可是我有一件重要的事情，不能参加了。对不起。让你难过了。', 'label': 1}, {'sentence': '可是我有一个重要的事情，不能参加。对不起。让你难过。', 'label': -1}), ({'sentence': '“安乐死”是一种生命的选择，现在对很多病人来说可能“生”比“死”还要苦：不能吃东西，总是吃药，不能去外面，一直在病房，有的病人不会说话。如果自己的亲朋好友是这个样子的话，我绝对受不了；可能钱的负担也不小；但是这不仅是钱的问题而且是心理上的问题。', 'label': 1}, {'sentence': '“安乐死”是一种生命的选择，现在很多病人可能“生”比“死”还要苦：不能吃东西，总是吃药，不能出去外面，一直在病房，有的病人不会说话。如果自己的亲朋好友就是这个样子的话，我绝对受不了；可能钱的负担也不少；但是这不仅是钱的问题是心理上的问题而且。', 'label': -1})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group pairs by new length bins based on the correct sentence length (0-9, ..., 100-109, 110+)\n",
        "new_length_bins = list(range(0, 111, 10)) + [float('inf')]\n",
        "new_length_labels = [f'{new_length_bins[i]}-{new_length_bins[i+1]-1}' for i in range(len(new_length_bins)-2)] + [f'{new_length_bins[-2]}+']\n",
        "\n",
        "from collections import defaultdict\n",
        "new_grouped_pairs = defaultdict(list)\n",
        "\n",
        "for correct_item, ungrammatical_item in test_pairs:\n",
        "    correct_len = len(correct_item[\"sentence\"])\n",
        "\n",
        "    # Find the correct bin for the correct sentence length\n",
        "    assigned_bin = None\n",
        "    for j in range(len(new_length_bins) - 1):\n",
        "        if new_length_bins[j] <= correct_len < new_length_bins[j+1]:\n",
        "            assigned_bin = new_length_labels[j]\n",
        "            break\n",
        "    # Handle the case for the last bin (>= 110)\n",
        "    if assigned_bin is None and correct_len >= new_length_bins[-2]:\n",
        "         if len(new_length_labels) > 0:\n",
        "             assigned_bin = new_length_labels[-1]\n",
        "\n",
        "\n",
        "    if assigned_bin:\n",
        "        # Append the original pair to the correct length bin\n",
        "        new_grouped_pairs[assigned_bin].append((correct_item, ungrammatical_item))\n",
        "\n",
        "# Print the number of pairs in each new length bin\n",
        "print(\"\\nNumber of pairs in each new length bin (based on correct sentence length):\")\n",
        "# Sort by label\n",
        "def sort_key(label):\n",
        "    if '-' in label:\n",
        "        try:\n",
        "            return int(label.split('-')[0])\n",
        "        except ValueError:\n",
        "            pass\n",
        "    elif '+' in label:\n",
        "         try:\n",
        "             return int(label.split('+')[0])\n",
        "         except ValueError:\n",
        "              pass\n",
        "    return label\n",
        "\n",
        "for label, pairs in sorted(new_grouped_pairs.items(), key=lambda item: sort_key(item[0])):\n",
        "    print(f\"Length bin '{label}': {len(pairs)} pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FydFFbnJm6Uq",
        "outputId": "e2d841e3-192b-493d-a345-9796907e9cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of pairs in each new length bin (based on correct sentence length):\n",
            "Length bin '0-9': 308 pairs\n",
            "Length bin '10-19': 1091 pairs\n",
            "Length bin '20-29': 657 pairs\n",
            "Length bin '30-39': 560 pairs\n",
            "Length bin '40-49': 481 pairs\n",
            "Length bin '50-59': 341 pairs\n",
            "Length bin '60-69': 248 pairs\n",
            "Length bin '70-79': 176 pairs\n",
            "Length bin '80-89': 114 pairs\n",
            "Length bin '90-99': 59 pairs\n",
            "Length bin '100-109': 42 pairs\n",
            "Length bin '110+': 72 pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnedDVp-PvQS"
      },
      "source": [
        "# Implementing the Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeX6ROFKAv9o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GrammarCheckDataset(Dataset):\n",
        "    # Modified to accept a list of sentence pairs and return tokenized pairs with labels\n",
        "    def __init__(self, data_pairs, tokenizer, max_length=256):\n",
        "        self.data_pairs = data_pairs # This will be a list of (correct_item, ungrammatical_item) tuples\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        correct_item, ungrammatical_item = self.data_pairs[idx]\n",
        "\n",
        "        correct_sentence = correct_item[\"sentence\"]\n",
        "        ungrammatical_sentence = ungrammatical_item[\"sentence\"]\n",
        "\n",
        "        # Tokenize the correct sentence\n",
        "        tokenized_correct = self.tokenizer(correct_sentence,\n",
        "                                          padding='max_length',\n",
        "                                          truncation=True,\n",
        "                                          max_length=self.max_length,\n",
        "                                          return_tensors='pt')\n",
        "\n",
        "        # Tokenize the ungrammatical sentence\n",
        "        tokenized_ungrammatical = self.tokenizer(ungrammatical_sentence,\n",
        "                                               padding='max_length',\n",
        "                                               truncation=True,\n",
        "                                               max_length=self.max_length,\n",
        "                                               return_tensors='pt')\n",
        "\n",
        "        # Return a dictionary containing tokenized correct and ungrammatical sentences and their labels\n",
        "        return {\n",
        "            \"correct_input_ids\": tokenized_correct['input_ids'].squeeze(0),\n",
        "            \"correct_attention_mask\": tokenized_correct['attention_mask'].squeeze(0),\n",
        "            \"ungrammatical_input_ids\": tokenized_ungrammatical['input_ids'].squeeze(0),\n",
        "            \"ungrammatical_attention_mask\": tokenized_ungrammatical['attention_mask'].squeeze(0),\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBydZRfHnaJL"
      },
      "source": [
        "# Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uaaTQSQVMxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91581c6d-5300-41c0-b8a8-ba2a4086517d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Check whether a GPU is available\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK7YxE2WBH7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a35d63-8d66-41b3-8faa-e4c31e10921c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h04A6D_ZpGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf19c46-71da-4719-85b0-856199604cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"Qwen/Qwen3-0.6B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "RzT4aV7OmG9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "6SdXF7GxovP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8 # Ensure batch size is even for paired data\n",
        "if batch_size % 2 != 0:\n",
        "    print(f\"Warning: Batch size {batch_size} is odd. Adjusting to {batch_size - 1} for paired data.\")\n",
        "    batch_size = batch_size - 1\n",
        "elif batch_size == 0:\n",
        "     print(f\"Warning: Batch size cannot be 0. Adjusting to 2 for paired data.\")\n",
        "     batch_size = 2\n",
        "\n",
        "\n",
        "# Create the datasets using the original pairs\n",
        "train_dataset = GrammarCheckDataset(train_pairs, tokenizer)\n",
        "validation_dataset = GrammarCheckDataset(val_pairs, tokenizer) # Use val_pairs directly\n",
        "test_dataset = GrammarCheckDataset(test_pairs, tokenizer) # Use test_pairs directly\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Inspect one batch\n",
        "print(\"Inspecting one batch from train_dataloader:\")\n",
        "for batch in train_dataloader:\n",
        "    print(\"Correct input_ids shape:\", batch[\"correct_input_ids\"].shape)\n",
        "    print(\"Correct attention_mask shape:\", batch[\"correct_attention_mask\"].shape)\n",
        "    print(\"Ungrammatical input_ids shape:\", batch[\"ungrammatical_input_ids\"].shape)\n",
        "    print(\"Ungrammatical attention_mask shape:\", batch[\"ungrammatical_attention_mask\"].shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "MPfgJjIEjT7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e6ae71-d5c9-4154-f368-20baf9cc8b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inspecting one batch from train_dataloader:\n",
            "Correct input_ids shape: torch.Size([8, 256])\n",
            "Correct attention_mask shape: torch.Size([8, 256])\n",
            "Ungrammatical input_ids shape: torch.Size([8, 256])\n",
            "Ungrammatical attention_mask shape: torch.Size([8, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Margin Loss"
      ],
      "metadata": {
        "id": "zbhkQu6ygVNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MarginLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super().__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, correct_logits, correct_attention_mask, correct_input_ids,\n",
        "                ungrammatical_logits, ungrammatical_attention_mask, ungrammatical_input_ids):\n",
        "\n",
        "        # Calculate log probability for correct sentences\n",
        "        shifted_correct_logits = correct_logits[:, :-1, :].contiguous()\n",
        "        correct_target_ids = correct_input_ids[:, 1:]\n",
        "        correct_target_mask = correct_attention_mask[:, 1:]\n",
        "        log_probs_correct_all = torch.log_softmax(shifted_correct_logits, dim=-1)\n",
        "        one_hot_correct_target_ids = F.one_hot(correct_target_ids, num_classes=log_probs_correct_all.size(-1)).float()\n",
        "        selected_log_probs_correct = torch.einsum('bsv,bsv->bs', log_probs_correct_all, one_hot_correct_target_ids)\n",
        "        masked_log_probs_correct = selected_log_probs_correct * correct_target_mask.float()\n",
        "        # Sum log probabilities over the sequence length for each sentence\n",
        "        sentence_log_probs_correct = masked_log_probs_correct.sum(dim=-1) # (batch_size,)\n",
        "\n",
        "        # Calculate log probability for ungrammatical sentences\n",
        "        shifted_ungrammatical_logits = ungrammatical_logits[:, :-1, :].contiguous()\n",
        "        ungrammatical_target_ids = ungrammatical_input_ids[:, 1:]\n",
        "        ungrammatical_target_mask = ungrammatical_attention_mask[:, 1:]\n",
        "        log_probs_ungrammatical_all = torch.log_softmax(shifted_ungrammatical_logits, dim=-1)\n",
        "        one_hot_ungrammatical_target_ids = F.one_hot(ungrammatical_target_ids, num_classes=log_probs_ungrammatical_all.size(-1)).float()\n",
        "        selected_log_probs_ungrammatical = torch.einsum('bsv,bsv->bs', log_probs_ungrammatical_all, one_hot_ungrammatical_target_ids)\n",
        "        masked_log_probs_ungrammatical = selected_log_probs_ungrammatical * ungrammatical_target_mask.float()\n",
        "        # Sum log probabilities over the sequence length for each sentence\n",
        "        sentence_log_probs_ungrammatical = masked_log_probs_ungrammatical.sum(dim=-1) # (batch_size,)\n",
        "\n",
        "        # Calculate the margin loss\n",
        "        # The loss is max(0, (log_prob_ungrammatical - log_prob_correct) + margin)\n",
        "        loss = torch.relu((sentence_log_probs_ungrammatical - sentence_log_probs_correct) + self.margin)\n",
        "\n",
        "        # Calculate the mean loss over the batch\n",
        "        batch_loss = torch.mean(loss)\n",
        "\n",
        "        return batch_loss"
      ],
      "metadata": {
        "id": "nQ854s3Kfh_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model fine-tuning"
      ],
      "metadata": {
        "id": "v54ZH8aqAR5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LoRA"
      ],
      "metadata": {
        "id": "WnGKTU4ZAmA5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02c9e887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac5a809-3517-44cf-9fee-c5b822b52c81"
      },
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "import torch\n",
        "\n",
        "# Define LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Get PEFT model\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,146,880 || all params: 597,196,800 || trainable%: 0.1920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training function"
      ],
      "metadata": {
        "id": "q5gRxnlrAr6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import copy\n",
        "import matplotlib.pyplot as plt # Import matplotlib\n",
        "\n",
        "def train(model, optimizer, train_dataloader, validation_dataloader, criterion, epochs=10, patience=3):\n",
        "\n",
        "    # Track and save the model with the best validation loss\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    # Lists to store metrics for plotting\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_accuracy': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        epoch_train_losses = []\n",
        "\n",
        "        # Iterate through all training batches\n",
        "        for batch in tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            # Move batch components to the device\n",
        "            correct_input_ids = batch[\"correct_input_ids\"].to(device)\n",
        "            correct_attention_mask = batch[\"correct_attention_mask\"].to(device)\n",
        "            ungrammatical_input_ids = batch[\"ungrammatical_input_ids\"].to(device)\n",
        "            ungrammatical_attention_mask = batch[\"ungrammatical_attention_mask\"].to(device)\n",
        "\n",
        "            # Reset the optimiser\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass for correct sentences\n",
        "            outputs_correct = model(input_ids=correct_input_ids, attention_mask=correct_attention_mask)\n",
        "            correct_logits = outputs_correct.logits # (batch_size, sequence_length, vocab_size)\n",
        "\n",
        "            # Forward pass for ungrammatical sentences\n",
        "            outputs_ungrammatical = model(input_ids=ungrammatical_input_ids, attention_mask=ungrammatical_attention_mask)\n",
        "            ungrammatical_logits = outputs_ungrammatical.logits # (batch_size, sequence_length, vocab_size)\n",
        "\n",
        "\n",
        "            # Calculate the MarginLoss\n",
        "            # Pass separate logits, attention_masks, and input_ids for correct and ungrammatical sentences\n",
        "            loss = criterion(correct_logits, correct_attention_mask, correct_input_ids,\n",
        "                             ungrammatical_logits, ungrammatical_attention_mask, ungrammatical_input_ids)\n",
        "\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_losses.append(loss.item())\n",
        "\n",
        "            # Print every 100 batches\n",
        "            if len(epoch_train_losses) % 100 == 0:\n",
        "                current_avg_train_loss = sum(epoch_train_losses)/len(epoch_train_losses) if len(epoch_train_losses) > 0 else 0\n",
        "                print(f\"\\nEpoch: {epoch + 1}, Batch: {len(epoch_train_losses)}, current train loss: {current_avg_train_loss:.4f}\")\n",
        "\n",
        "\n",
        "        # Print the loss at the end of every epoch\n",
        "        # Calculate the final average train loss for the epoch\n",
        "        final_avg_train_loss = sum(epoch_train_losses)/len(epoch_train_losses) if len(epoch_train_losses) > 0 else 0\n",
        "        print(f\"\\nEpoch: {epoch + 1}, processed {len(epoch_train_losses)} batches, final average train loss: {final_avg_train_loss:.4f}\")\n",
        "        history['train_loss'].append(final_avg_train_loss) # Store train loss\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        epoch_val_losses = []\n",
        "        correct_predictions = 0\n",
        "        total_pairs_evaluated = 0 # Count pairs for accuracy calculation\n",
        "\n",
        "        # Disable gradient calculation for validation\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm.tqdm(validation_dataloader, desc=f\"Epoch {epoch+1}/{epochs} (Validation)\"):\n",
        "                # Move batch components to the device\n",
        "                correct_input_ids = batch[\"correct_input_ids\"].to(device)\n",
        "                correct_attention_mask = batch[\"correct_attention_mask\"].to(device)\n",
        "                ungrammatical_input_ids = batch[\"ungrammatical_input_ids\"].to(device)\n",
        "                ungrammatical_attention_mask = batch[\"ungrammatical_attention_mask\"].to(device)\n",
        "\n",
        "\n",
        "                # Forward pass for correct sentences\n",
        "                outputs_correct = model(input_ids=correct_input_ids, attention_mask=correct_attention_mask)\n",
        "                correct_logits = outputs_correct.logits\n",
        "\n",
        "                # Forward pass for ungrammatical sentences\n",
        "                outputs_ungrammatical = model(input_ids=ungrammatical_input_ids, attention_mask=ungrammatical_attention_mask)\n",
        "                ungrammatical_logits = outputs_ungrammatical.logits\n",
        "\n",
        "\n",
        "                # Calculate validation loss using the custom criterion\n",
        "                val_loss = criterion(correct_logits, correct_attention_mask, correct_input_ids,\n",
        "                                      ungrammatical_logits, ungrammatical_attention_mask, ungrammatical_input_ids)\n",
        "                epoch_val_losses.append(val_loss.item())\n",
        "\n",
        "                # Calculate Accuracy\n",
        "                # Recalculate sentence log probabilities based on the logits\n",
        "\n",
        "                # For correct sentences\n",
        "                shifted_correct_logits = correct_logits[:, :-1, :].contiguous()\n",
        "                correct_target_ids = correct_input_ids[:, 1:]\n",
        "                correct_target_mask = correct_attention_mask[:, 1:]\n",
        "                log_probs_correct_all = torch.log_softmax(shifted_correct_logits, dim=-1)\n",
        "                one_hot_correct_target_ids = F.one_hot(correct_target_ids, num_classes=log_probs_correct_all.size(-1)).float()\n",
        "                selected_log_probs_correct = torch.einsum('bsv,bsv->bs', log_probs_correct_all, one_hot_correct_target_ids)\n",
        "                masked_log_probs_correct = selected_log_probs_correct * correct_target_mask.float()\n",
        "                sentence_log_probs_correct = masked_log_probs_correct.sum(dim=-1) # (batch_size,)\n",
        "\n",
        "\n",
        "                # For ungrammatical sentences\n",
        "                shifted_ungrammatical_logits = ungrammatical_logits[:, :-1, :].contiguous()\n",
        "                ungrammatical_target_ids = ungrammatical_input_ids[:, 1:]\n",
        "                ungrammatical_target_mask = ungrammatical_attention_mask[:, 1:]\n",
        "                log_probs_ungrammatical_all = torch.log_softmax(shifted_ungrammatical_logits, dim=-1)\n",
        "                one_hot_ungrammatical_target_ids = F.one_hot(ungrammatical_target_ids, num_classes=log_probs_ungrammatical_all.size(-1)).float()\n",
        "                selected_log_probs_ungrammatical = torch.einsum('bsv,bsv->bs', log_probs_ungrammatical_all, one_hot_ungrammatical_target_ids)\n",
        "                masked_log_probs_ungrammatical = selected_log_probs_ungrammatical * ungrammatical_target_mask.float()\n",
        "                sentence_log_probs_ungrammatical = masked_log_probs_ungrammatical.sum(dim=-1) # (batch_size,)\n",
        "\n",
        "\n",
        "                # Compare log probabilities within each pair\n",
        "                for i in range(sentence_log_probs_correct.shape[0]):\n",
        "                    if sentence_log_probs_correct[i] > sentence_log_probs_ungrammatical[i]:\n",
        "                        correct_predictions += 1\n",
        "                    total_pairs_evaluated += 1 # Count each pair\n",
        "\n",
        "            avg_val_loss = sum(epoch_val_losses)/len(epoch_val_losses) if len(epoch_val_losses) > 0 else 0\n",
        "            val_accuracy = (correct_predictions / total_pairs_evaluated) * 100 if total_pairs_evaluated > 0 else 0\n",
        "\n",
        "            print(f\"\\nEpoch: {epoch+1}, average validation loss: {avg_val_loss:.4f}, validation accuracy: {val_accuracy:.2f}%\")\n",
        "            history['val_loss'].append(avg_val_loss) # Store val loss\n",
        "            history['val_accuracy'].append(val_accuracy) # Store val accuracy\n",
        "\n",
        "\n",
        "        # Early Stopping Check\n",
        "        # Use the average validation loss for early stopping\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_no_improve = 0\n",
        "            # Save the model state dictionary when validation loss improves\n",
        "            # Move each tensor within the state dictionary to CPU\n",
        "            best_model_state = {k: v.cpu() for k, v in copy.deepcopy(model.state_dict()).items()}\n",
        "            print(f\"Validation loss improved. Saving model state.\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"Validation loss did not improve. Epochs with no improvement: {epochs_no_improve}/{patience}\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs. Validation loss did not improve for {patience} consecutive epochs.\")\n",
        "            break\n",
        "\n",
        "        # End of Epoch\n",
        "        model.train()\n",
        "\n",
        "    print(\"Training finished.\")\n",
        "\n",
        "    # Load the best model state after training\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        print(\"Loaded model state with the best validation loss.\")\n",
        "    else:\n",
        "        print(\"No model state was saved (perhaps training did not complete at least one epoch).\")\n",
        "\n",
        "    return model, history # Return the best model and training history"
      ],
      "metadata": {
        "id": "Rvt_5BcrnPd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = train(\n",
        "    model,\n",
        "    optimizer,\n",
        "    train_dataloader,\n",
        "    validation_dataloader,\n",
        "    criterion=MarginLoss(),\n",
        "    epochs=10,\n",
        "    patience=3\n",
        ")\n",
        "\n",
        "print(\"Training completed.\")"
      ],
      "metadata": {
        "id": "B0maj22iM-jb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db8d2bb-05a6-402b-c55f-b72abf8ee60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:   2%|▏         | 100/4149 [01:23<55:33,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 100, current train loss: 0.9166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:   5%|▍         | 200/4149 [02:45<54:18,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 200, current train loss: 0.9839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:   7%|▋         | 300/4149 [04:07<52:51,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 300, current train loss: 0.8634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  10%|▉         | 400/4149 [05:30<51:26,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 400, current train loss: 0.8645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  12%|█▏        | 500/4149 [06:52<50:04,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 500, current train loss: 0.8355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  14%|█▍        | 600/4149 [08:15<48:42,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 600, current train loss: 0.8524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  17%|█▋        | 700/4149 [09:37<47:18,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 700, current train loss: 0.8255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  19%|█▉        | 800/4149 [10:59<45:56,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 800, current train loss: 0.8057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  22%|██▏       | 900/4149 [12:22<44:35,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 900, current train loss: 0.7914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  24%|██▍       | 1000/4149 [13:44<43:12,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1000, current train loss: 0.7764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  27%|██▋       | 1100/4149 [15:06<41:53,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1100, current train loss: 0.7548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  29%|██▉       | 1200/4149 [16:29<40:28,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1200, current train loss: 0.7542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  31%|███▏      | 1300/4149 [17:51<39:05,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1300, current train loss: 0.7492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  34%|███▎      | 1400/4149 [19:14<37:47,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1400, current train loss: 0.7459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  36%|███▌      | 1500/4149 [20:36<36:22,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1500, current train loss: 0.7383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  39%|███▊      | 1600/4149 [21:58<35:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1600, current train loss: 0.7301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  41%|████      | 1700/4149 [23:21<33:36,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1700, current train loss: 0.7198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  43%|████▎     | 1800/4149 [24:43<32:15,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1800, current train loss: 0.7203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  46%|████▌     | 1900/4149 [26:05<30:51,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 1900, current train loss: 0.7170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  48%|████▊     | 2000/4149 [27:28<29:31,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2000, current train loss: 0.7132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  51%|█████     | 2100/4149 [28:50<28:07,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2100, current train loss: 0.7060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  53%|█████▎    | 2200/4149 [30:12<26:44,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2200, current train loss: 0.7044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  55%|█████▌    | 2300/4149 [31:35<25:22,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2300, current train loss: 0.7047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  58%|█████▊    | 2400/4149 [32:57<24:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2400, current train loss: 0.7020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  60%|██████    | 2500/4149 [34:20<22:37,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2500, current train loss: 0.6973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  63%|██████▎   | 2600/4149 [35:42<21:15,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2600, current train loss: 0.7011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  65%|██████▌   | 2700/4149 [37:04<19:53,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2700, current train loss: 0.7004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  67%|██████▋   | 2800/4149 [38:27<18:31,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2800, current train loss: 0.6977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  70%|██████▉   | 2900/4149 [39:49<17:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 2900, current train loss: 0.6975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  72%|███████▏  | 3000/4149 [41:12<15:45,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3000, current train loss: 0.6957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  75%|███████▍  | 3100/4149 [42:34<14:23,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3100, current train loss: 0.6899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  77%|███████▋  | 3200/4149 [43:56<13:01,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3200, current train loss: 0.6869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  80%|███████▉  | 3300/4149 [45:19<11:39,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3300, current train loss: 0.6848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  82%|████████▏ | 3400/4149 [46:41<10:17,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3400, current train loss: 0.6827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  84%|████████▍ | 3500/4149 [48:03<08:54,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3500, current train loss: 0.6812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  87%|████████▋ | 3600/4149 [49:26<07:31,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3600, current train loss: 0.6808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  89%|████████▉ | 3700/4149 [50:48<06:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3700, current train loss: 0.6797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  92%|█████████▏| 3800/4149 [52:10<04:47,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3800, current train loss: 0.6801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  94%|█████████▍| 3900/4149 [53:33<03:24,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 3900, current train loss: 0.6765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  96%|█████████▋| 4000/4149 [54:55<02:02,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 4000, current train loss: 0.6765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  99%|█████████▉| 4100/4149 [56:18<00:40,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Batch: 4100, current train loss: 0.6733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 4149/4149 [56:58<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, processed 4149 batches, final average train loss: 0.6718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 (Validation): 100%|██████████| 519/519 [03:28<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, average validation loss: 0.5288, validation accuracy: 87.83%\n",
            "Validation loss improved. Saving model state.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:   2%|▏         | 100/4149 [01:22<55:33,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 100, current train loss: 0.4101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:   5%|▍         | 200/4149 [02:44<54:11,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 200, current train loss: 0.3903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:   7%|▋         | 300/4149 [04:07<52:50,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 300, current train loss: 0.3773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  10%|▉         | 400/4149 [05:29<51:24,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 400, current train loss: 0.4094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  12%|█▏        | 500/4149 [06:51<50:04,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 500, current train loss: 0.4328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  14%|█▍        | 600/4149 [08:14<48:42,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 600, current train loss: 0.4276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  17%|█▋        | 700/4149 [09:36<47:18,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 700, current train loss: 0.4113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  19%|█▉        | 800/4149 [10:59<45:57,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 800, current train loss: 0.4169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  22%|██▏       | 900/4149 [12:21<44:36,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 900, current train loss: 0.4141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  24%|██▍       | 1000/4149 [13:43<43:12,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1000, current train loss: 0.4186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  27%|██▋       | 1100/4149 [15:06<41:50,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1100, current train loss: 0.4243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  29%|██▉       | 1200/4149 [16:28<40:26,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1200, current train loss: 0.4209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  31%|███▏      | 1300/4149 [17:50<39:05,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1300, current train loss: 0.4223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  34%|███▎      | 1400/4149 [19:13<37:44,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1400, current train loss: 0.4210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  36%|███▌      | 1500/4149 [20:35<36:19,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1500, current train loss: 0.4182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  39%|███▊      | 1600/4149 [21:57<34:58,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1600, current train loss: 0.4113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  41%|████      | 1700/4149 [23:19<33:35,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1700, current train loss: 0.4087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  43%|████▎     | 1800/4149 [24:42<32:14,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1800, current train loss: 0.4059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  46%|████▌     | 1900/4149 [26:04<30:51,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 1900, current train loss: 0.4051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  48%|████▊     | 2000/4149 [27:26<29:28,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2000, current train loss: 0.4071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  51%|█████     | 2100/4149 [28:49<28:05,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2100, current train loss: 0.4036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  53%|█████▎    | 2200/4149 [30:11<26:44,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2200, current train loss: 0.4050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  55%|█████▌    | 2300/4149 [31:34<25:22,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2300, current train loss: 0.4081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  58%|█████▊    | 2400/4149 [32:56<24:01,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2400, current train loss: 0.4103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  60%|██████    | 2500/4149 [34:18<22:37,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2500, current train loss: 0.4142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  63%|██████▎   | 2600/4149 [35:41<21:16,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2600, current train loss: 0.4117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  65%|██████▌   | 2700/4149 [37:03<19:52,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2700, current train loss: 0.4140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  67%|██████▋   | 2800/4149 [38:25<18:30,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2800, current train loss: 0.4122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  70%|██████▉   | 2900/4149 [39:48<17:08,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 2900, current train loss: 0.4159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  72%|███████▏  | 3000/4149 [41:10<15:46,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3000, current train loss: 0.4178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  75%|███████▍  | 3100/4149 [42:32<14:23,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3100, current train loss: 0.4174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  77%|███████▋  | 3200/4149 [43:55<13:02,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3200, current train loss: 0.4166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  80%|███████▉  | 3300/4149 [45:17<11:38,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3300, current train loss: 0.4137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  82%|████████▏ | 3400/4149 [46:40<10:16,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3400, current train loss: 0.4140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  84%|████████▍ | 3500/4149 [48:02<08:54,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3500, current train loss: 0.4122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  87%|████████▋ | 3600/4149 [49:25<07:32,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3600, current train loss: 0.4134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  89%|████████▉ | 3700/4149 [50:47<06:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3700, current train loss: 0.4143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  92%|█████████▏| 3800/4149 [52:09<04:47,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3800, current train loss: 0.4136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  94%|█████████▍| 3900/4149 [53:32<03:24,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 3900, current train loss: 0.4137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  96%|█████████▋| 4000/4149 [54:54<02:02,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 4000, current train loss: 0.4153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:  99%|█████████▉| 4100/4149 [56:16<00:40,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Batch: 4100, current train loss: 0.4153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 4149/4149 [56:57<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, processed 4149 batches, final average train loss: 0.4147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 (Validation): 100%|██████████| 519/519 [03:28<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, average validation loss: 0.5120, validation accuracy: 88.07%\n",
            "Validation loss improved. Saving model state.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:   2%|▏         | 100/4149 [01:22<55:39,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 100, current train loss: 0.1836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:   5%|▍         | 200/4149 [02:44<54:13,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 200, current train loss: 0.1873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:   7%|▋         | 300/4149 [04:07<52:49,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 300, current train loss: 0.1955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  10%|▉         | 400/4149 [05:29<51:26,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 400, current train loss: 0.2052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  12%|█▏        | 500/4149 [06:52<50:03,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 500, current train loss: 0.2083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  14%|█▍        | 600/4149 [08:14<48:42,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 600, current train loss: 0.2121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  17%|█▋        | 700/4149 [09:37<47:20,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 700, current train loss: 0.2087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  19%|█▉        | 800/4149 [10:59<45:58,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 800, current train loss: 0.2112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  22%|██▏       | 900/4149 [12:21<44:33,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 900, current train loss: 0.2234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  24%|██▍       | 1000/4149 [13:44<43:11,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1000, current train loss: 0.2272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  27%|██▋       | 1100/4149 [15:06<41:50,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1100, current train loss: 0.2342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  29%|██▉       | 1200/4149 [16:28<40:29,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1200, current train loss: 0.2322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  31%|███▏      | 1300/4149 [17:51<39:04,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1300, current train loss: 0.2329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  34%|███▎      | 1400/4149 [19:13<37:43,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1400, current train loss: 0.2322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  36%|███▌      | 1500/4149 [20:35<36:23,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1500, current train loss: 0.2375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  39%|███▊      | 1600/4149 [21:58<34:58,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1600, current train loss: 0.2389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  41%|████      | 1700/4149 [23:20<33:36,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1700, current train loss: 0.2384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  43%|████▎     | 1800/4149 [24:43<32:16,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1800, current train loss: 0.2375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  46%|████▌     | 1900/4149 [26:05<30:51,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 1900, current train loss: 0.2386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  48%|████▊     | 2000/4149 [27:27<29:31,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2000, current train loss: 0.2385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  51%|█████     | 2100/4149 [28:50<28:08,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2100, current train loss: 0.2380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  53%|█████▎    | 2200/4149 [30:12<26:45,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2200, current train loss: 0.2416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  55%|█████▌    | 2300/4149 [31:34<25:22,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2300, current train loss: 0.2421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  58%|█████▊    | 2400/4149 [32:57<24:03,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2400, current train loss: 0.2438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  60%|██████    | 2500/4149 [34:19<22:37,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2500, current train loss: 0.2534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  63%|██████▎   | 2600/4149 [35:42<21:15,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2600, current train loss: 0.2533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  65%|██████▌   | 2700/4149 [37:04<19:53,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2700, current train loss: 0.2540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  67%|██████▋   | 2800/4149 [38:26<18:30,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2800, current train loss: 0.2556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  70%|██████▉   | 2900/4149 [39:49<17:08,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 2900, current train loss: 0.2548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  72%|███████▏  | 3000/4149 [41:11<16:37,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3000, current train loss: 0.2575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  75%|███████▍  | 3100/4149 [42:34<14:23,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3100, current train loss: 0.2573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  77%|███████▋  | 3200/4149 [43:56<13:00,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3200, current train loss: 0.2596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  80%|███████▉  | 3300/4149 [45:18<11:38,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3300, current train loss: 0.2582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  82%|████████▏ | 3400/4149 [46:41<10:16,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3400, current train loss: 0.2616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  84%|████████▍ | 3500/4149 [48:03<08:54,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3500, current train loss: 0.2588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  87%|████████▋ | 3600/4149 [49:25<07:32,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3600, current train loss: 0.2576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  89%|████████▉ | 3700/4149 [50:47<06:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3700, current train loss: 0.2591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  92%|█████████▏| 3800/4149 [52:10<04:47,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3800, current train loss: 0.2579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  94%|█████████▍| 3900/4149 [53:32<03:25,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 3900, current train loss: 0.2595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  96%|█████████▋| 4000/4149 [54:55<02:02,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 4000, current train loss: 0.2600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:  99%|█████████▉| 4100/4149 [56:17<00:40,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Batch: 4100, current train loss: 0.2588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 4149/4149 [56:57<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, processed 4149 batches, final average train loss: 0.2598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 (Validation): 100%|██████████| 519/519 [03:29<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, average validation loss: 0.5460, validation accuracy: 88.26%\n",
            "Validation loss did not improve. Epochs with no improvement: 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:   2%|▏         | 100/4149 [01:22<55:34,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 100, current train loss: 0.1018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:   5%|▍         | 200/4149 [02:44<54:10,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 200, current train loss: 0.1098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:   7%|▋         | 300/4149 [04:07<52:46,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 300, current train loss: 0.1312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  10%|▉         | 400/4149 [05:29<51:26,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 400, current train loss: 0.1437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  12%|█▏        | 500/4149 [06:51<50:06,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 500, current train loss: 0.1411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  14%|█▍        | 600/4149 [08:14<48:41,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 600, current train loss: 0.1428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  17%|█▋        | 700/4149 [09:36<47:21,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 700, current train loss: 0.1431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  19%|█▉        | 800/4149 [10:58<45:55,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 800, current train loss: 0.1447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  22%|██▏       | 900/4149 [12:21<44:34,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 900, current train loss: 0.1480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  24%|██▍       | 1000/4149 [13:43<43:13,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1000, current train loss: 0.1521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  27%|██▋       | 1100/4149 [15:05<41:48,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1100, current train loss: 0.1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  29%|██▉       | 1200/4149 [16:28<40:27,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1200, current train loss: 0.1601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  31%|███▏      | 1300/4149 [17:50<39:06,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1300, current train loss: 0.1568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  34%|███▎      | 1400/4149 [19:13<37:42,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1400, current train loss: 0.1594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  36%|███▌      | 1500/4149 [20:35<36:20,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1500, current train loss: 0.1615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  39%|███▊      | 1600/4149 [21:57<35:02,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1600, current train loss: 0.1631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  41%|████      | 1700/4149 [23:20<33:35,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1700, current train loss: 0.1590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  43%|████▎     | 1800/4149 [24:42<32:12,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1800, current train loss: 0.1605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  46%|████▌     | 1900/4149 [26:04<30:50,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 1900, current train loss: 0.1630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  48%|████▊     | 2000/4149 [27:27<29:28,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2000, current train loss: 0.1644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  51%|█████     | 2100/4149 [28:49<28:07,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2100, current train loss: 0.1648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  53%|█████▎    | 2200/4149 [30:11<26:46,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2200, current train loss: 0.1655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  55%|█████▌    | 2300/4149 [31:34<25:22,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2300, current train loss: 0.1660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  58%|█████▊    | 2400/4149 [32:56<23:59,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2400, current train loss: 0.1671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  60%|██████    | 2500/4149 [34:18<22:37,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2500, current train loss: 0.1686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  63%|██████▎   | 2600/4149 [35:41<21:14,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2600, current train loss: 0.1690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  65%|██████▌   | 2700/4149 [37:03<19:52,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2700, current train loss: 0.1688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  67%|██████▋   | 2800/4149 [38:26<18:30,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2800, current train loss: 0.1684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  70%|██████▉   | 2900/4149 [39:48<17:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 2900, current train loss: 0.1704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  72%|███████▏  | 3000/4149 [41:10<15:45,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3000, current train loss: 0.1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  75%|███████▍  | 3100/4149 [42:33<14:23,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3100, current train loss: 0.1700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  77%|███████▋  | 3200/4149 [43:55<13:01,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3200, current train loss: 0.1715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  80%|███████▉  | 3300/4149 [45:17<11:38,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3300, current train loss: 0.1735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  82%|████████▏ | 3400/4149 [46:40<10:17,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3400, current train loss: 0.1761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  84%|████████▍ | 3500/4149 [48:02<08:55,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3500, current train loss: 0.1792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  87%|████████▋ | 3600/4149 [49:24<07:32,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3600, current train loss: 0.1852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  89%|████████▉ | 3700/4149 [50:47<06:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3700, current train loss: 0.1865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  92%|█████████▏| 3800/4149 [52:09<04:47,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3800, current train loss: 0.1881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  94%|█████████▍| 3900/4149 [53:32<03:24,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 3900, current train loss: 0.1897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  96%|█████████▋| 4000/4149 [54:54<02:02,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 4000, current train loss: 0.1923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:  99%|█████████▉| 4100/4149 [56:16<00:40,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Batch: 4100, current train loss: 0.1951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 4149/4149 [56:57<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, processed 4149 batches, final average train loss: 0.1944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 (Validation): 100%|██████████| 519/519 [03:28<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, average validation loss: 0.5798, validation accuracy: 87.39%\n",
            "Validation loss did not improve. Epochs with no improvement: 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:   2%|▏         | 100/4149 [01:22<55:33,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 100, current train loss: 0.1176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:   5%|▍         | 200/4149 [02:44<54:11,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 200, current train loss: 0.1259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:   7%|▋         | 300/4149 [04:06<52:50,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 300, current train loss: 0.1234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  10%|▉         | 400/4149 [05:29<51:27,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 400, current train loss: 0.1227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  12%|█▏        | 500/4149 [06:51<50:04,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 500, current train loss: 0.1206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  14%|█▍        | 600/4149 [08:13<48:40,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 600, current train loss: 0.1225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  17%|█▋        | 700/4149 [09:36<47:22,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 700, current train loss: 0.1254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  19%|█▉        | 800/4149 [10:58<45:57,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 800, current train loss: 0.1300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  22%|██▏       | 900/4149 [12:21<44:39,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 900, current train loss: 0.1370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  24%|██▍       | 1000/4149 [13:43<43:16,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1000, current train loss: 0.1383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  27%|██▋       | 1100/4149 [15:06<41:51,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1100, current train loss: 0.1336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  29%|██▉       | 1200/4149 [16:28<40:30,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1200, current train loss: 0.1331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  31%|███▏      | 1300/4149 [17:51<39:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1300, current train loss: 0.1304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  34%|███▎      | 1400/4149 [19:13<37:47,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1400, current train loss: 0.1298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  36%|███▌      | 1500/4149 [20:35<36:25,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1500, current train loss: 0.1290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  39%|███▊      | 1600/4149 [21:58<34:57,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1600, current train loss: 0.1273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  41%|████      | 1700/4149 [23:20<33:36,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1700, current train loss: 0.1279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  43%|████▎     | 1800/4149 [24:42<32:14,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1800, current train loss: 0.1258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  46%|████▌     | 1900/4149 [26:05<30:51,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 1900, current train loss: 0.1265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  48%|████▊     | 2000/4149 [27:27<29:28,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2000, current train loss: 0.1283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  51%|█████     | 2100/4149 [28:50<28:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2100, current train loss: 0.1283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  53%|█████▎    | 2200/4149 [30:12<26:43,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2200, current train loss: 0.1283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  55%|█████▌    | 2300/4149 [31:35<25:23,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2300, current train loss: 0.1311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  58%|█████▊    | 2400/4149 [32:57<23:59,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2400, current train loss: 0.1314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  60%|██████    | 2500/4149 [34:19<22:37,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2500, current train loss: 0.1318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  63%|██████▎   | 2600/4149 [35:42<21:15,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2600, current train loss: 0.1319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  65%|██████▌   | 2700/4149 [37:04<19:54,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2700, current train loss: 0.1338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  67%|██████▋   | 2800/4149 [38:26<18:29,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2800, current train loss: 0.1357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  70%|██████▉   | 2900/4149 [39:49<17:07,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 2900, current train loss: 0.1342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  72%|███████▏  | 3000/4149 [41:11<15:46,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3000, current train loss: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  75%|███████▍  | 3100/4149 [42:33<14:23,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3100, current train loss: 0.1363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  77%|███████▋  | 3200/4149 [43:56<13:01,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3200, current train loss: 0.1356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  80%|███████▉  | 3300/4149 [45:18<11:39,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3300, current train loss: 0.1353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  82%|████████▏ | 3400/4149 [46:41<10:49,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3400, current train loss: 0.1370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  84%|████████▍ | 3500/4149 [48:03<08:54,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3500, current train loss: 0.1378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  87%|████████▋ | 3600/4149 [49:25<07:32,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3600, current train loss: 0.1364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  89%|████████▉ | 3700/4149 [50:48<06:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3700, current train loss: 0.1361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  92%|█████████▏| 3800/4149 [52:10<04:47,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3800, current train loss: 0.1350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  94%|█████████▍| 3900/4149 [53:32<03:25,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 3900, current train loss: 0.1357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  96%|█████████▋| 4000/4149 [54:55<02:02,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 4000, current train loss: 0.1362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  99%|█████████▉| 4100/4149 [56:17<00:40,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Batch: 4100, current train loss: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 4149/4149 [56:57<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, processed 4149 batches, final average train loss: 0.1372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 (Validation): 100%|██████████| 519/519 [03:28<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, average validation loss: 0.5369, validation accuracy: 88.72%\n",
            "Validation loss did not improve. Epochs with no improvement: 3/3\n",
            "Early stopping triggered after 5 epochs. Validation loss did not improve for 3 consecutive epochs.\n",
            "Training finished.\n",
            "Loaded model state with the best validation loss.\n",
            "Training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming the train function was called and returned 'history'\n",
        "# Example: best_model, history = train(...)\n",
        "\n",
        "if 'history' in locals() and history is not None:\n",
        "    # Create a figure with two subplots (1 row, 2 columns)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Plot Loss on the left subplot\n",
        "    axes[0].plot(history['train_loss'], label='Training Loss')\n",
        "    axes[0].plot(history['val_loss'], label='Validation Loss')\n",
        "    axes[0].set_title('Training and Validation Loss per Epoch')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # Plot Accuracy on the right subplot\n",
        "    axes[1].plot(history['val_accuracy'], label='Validation Accuracy', color='green')\n",
        "    axes[1].set_title('Validation Accuracy per Epoch')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy (%)')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    # Adjust layout to prevent titles/labels from overlapping\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Training history not available. Please run the training cell first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9_PGpqkBiQN",
        "outputId": "92bdd22d-8476-4aa7-f8b7-4a8812a784b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training history not available. Please run the training cell first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ],
      "metadata": {
        "id": "2JlBR2LHnCpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qwen3-0.6B"
      ],
      "metadata": {
        "id": "nyt09gytZm5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample_logprob(sample, model):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    # Extract input_ids and attention_mask from the sample\n",
        "    input_ids = sample[\"input_ids\"].unsqueeze(0).to(device) # Add batch dimension: (1, sequence_length)\n",
        "    attention_mask = sample[\"attention_mask\"].unsqueeze(0).to(device)\n",
        "\n",
        "    # Disable gradient calculation because the model is not used for training\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # logits shape: (batch_size, seq_len, vocab_size)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Calculate log probabilities for each token (except first start token)\n",
        "    total_log_prob = 0.0\n",
        "    for i in range(1, input_ids.shape[1]):\n",
        "        # Get logits for the previous position predicting the current token\n",
        "        if attention_mask[0, i] == 1:\n",
        "            current_logits = logits[0, i-1, :]\n",
        "            current_token_id = input_ids[0, i]\n",
        "            log_prob = torch.log_softmax(current_logits, dim=-1)[current_token_id].item()\n",
        "            total_log_prob += log_prob\n",
        "\n",
        "    return total_log_prob"
      ],
      "metadata": {
        "id": "nd4PfIIwnRMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "correct_pairs = 0\n",
        "total_pairs = 0\n",
        "\n",
        "# Iterate directly over the test_dataset which now yields paired data\n",
        "for pair_data in tqdm.tqdm(test_dataset, desc=\"Evaluating model\"):\n",
        "    total_pairs += 1\n",
        "\n",
        "    # Extract correct and ungrammatical sentence data from the paired item\n",
        "    correct_sample = {\n",
        "        \"input_ids\": pair_data[\"correct_input_ids\"],\n",
        "        \"attention_mask\": pair_data[\"correct_attention_mask\"],\n",
        "    }\n",
        "    ungrammatical_sample = {\n",
        "        \"input_ids\": pair_data[\"ungrammatical_input_ids\"],\n",
        "        \"attention_mask\": pair_data[\"ungrammatical_attention_mask\"],\n",
        "    }\n",
        "\n",
        "    # Calculate log probabilities for the pair\n",
        "    # Ensure the model is on the correct device before calling get_sample_logprob\n",
        "    prob_correct = get_sample_logprob(correct_sample, model)\n",
        "    prob_ungrammatical = get_sample_logprob(ungrammatical_sample, model)\n",
        "\n",
        "    # Calculate overall correct count\n",
        "    if prob_correct > prob_ungrammatical:\n",
        "        correct_pairs += 1\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = (correct_pairs / total_pairs) * 100 if total_pairs > 0 else 0\n",
        "\n",
        "print(f\"\\nFinal Test Set Accuracy (Fine-tuned Model): {overall_accuracy:.2f}% ({correct_pairs}/{total_pairs})\")"
      ],
      "metadata": {
        "id": "bDI_NJSbsr7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d6237d6-eef5-414b-ef6f-49bd9170e936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating model: 100%|██████████| 4149/4149 [10:42<00:00,  6.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Set Accuracy (Fine-tuned Model): 88.12% (3656/4149)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "# No need to import defaultdict here as new_grouped_pairs is already a defaultdict\n",
        "\n",
        "# The length bins and grouped test pairs (new_grouped_pairs) are already defined and calculated in cell FydFFbnJm6Uq.\n",
        "# We will reuse them directly.\n",
        "\n",
        "# Evaluate accuracy and calculate softmax probability over the two sentence log probabilities for each length bin\n",
        "print(\"\\nEvaluating accuracy and calculating softmax probability over two sentence log probabilities for each length bin:\")\n",
        "\n",
        "new_length_group_accuracy = {}\n",
        "new_length_group_metric = {} # This will store the average of the softmax probability over the two sentence log probabilities\n",
        "\n",
        "# Sort by label for ordered output (reuse sort_key)\n",
        "def sort_key(label):\n",
        "    if '-' in label:\n",
        "        try:\n",
        "            return int(label.split('-')[0])\n",
        "        except ValueError:\n",
        "            pass\n",
        "    elif '+' in label:\n",
        "         try:\n",
        "             return int(label.split('+')[0])\n",
        "         except ValueError:\n",
        "              pass\n",
        "    return label\n",
        "\n",
        "# Ensure the model is in evaluation mode and on the correct device\n",
        "# Access the model object from the best_model tuple (it's the first element)\n",
        "eval_model = best_model[0]\n",
        "eval_model.eval()\n",
        "eval_model.to(device)\n",
        "\n",
        "# Use the already calculated new_grouped_pairs (which contains the test pairs grouped by length)\n",
        "for label, pairs in sorted(new_grouped_pairs.items(), key=lambda item: sort_key(item[0])):\n",
        "    correct_predictions_bin = 0\n",
        "    total_pairs_bin = len(pairs)\n",
        "    group_metric_sum = 0.0 # Sum of softmax probabilities over two sentence log probabilities for this bin\n",
        "\n",
        "\n",
        "    if total_pairs_bin == 0:\n",
        "        print(f\"Length bin '{label}': 0 pairs, Accuracy: N/A, Average Softmax Probability over Sentence Log Probabilities: N/A\")\n",
        "        continue\n",
        "\n",
        "    # Create a dataset and dataloader for the current bin's pairs\n",
        "    # GrammarCheckDataset is designed to take a list of pairs\n",
        "    bin_dataset = GrammarCheckDataset(pairs, tokenizer)\n",
        "    # Reduce batch size for evaluation to mitigate OutOfMemoryError\n",
        "    evaluation_batch_size = 4 # You can adjust this value based on your GPU memory\n",
        "    bin_dataloader = DataLoader(bin_dataset, batch_size=evaluation_batch_size) # Use a smaller batch size for evaluation\n",
        "\n",
        "    for batch in tqdm.tqdm(bin_dataloader, desc=f\"Processing bin '{label}'\"):\n",
        "        correct_input_ids = batch[\"correct_input_ids\"].to(device)\n",
        "        correct_attention_mask = batch[\"correct_attention_mask\"].to(device)\n",
        "        ungrammatical_input_ids = batch[\"ungrammatical_input_ids\"].to(device)\n",
        "        ungrammatical_attention_mask = batch[\"ungrammatical_attention_mask\"].to(device)\n",
        "\n",
        "\n",
        "        # Forward pass for correct and ungrammatical sentences using eval_model\n",
        "        with torch.no_grad():\n",
        "            outputs_correct = eval_model(input_ids=correct_input_ids, attention_mask=correct_attention_mask)\n",
        "            correct_logits = outputs_correct.logits\n",
        "\n",
        "            outputs_ungrammatical = eval_model(input_ids=ungrammatical_input_ids, attention_mask=ungrammatical_attention_mask)\n",
        "            ungrammatical_logits = outputs_ungrammatical.logits\n",
        "\n",
        "\n",
        "        # Calculate sentence log probabilities\n",
        "        # For correct sentences\n",
        "        shifted_correct_logits = correct_logits[:, :-1, :].contiguous()\n",
        "        correct_target_ids = correct_input_ids[:, 1:]\n",
        "        correct_target_mask = correct_attention_mask[:, 1:]\n",
        "        log_probs_correct_all = torch.log_softmax(shifted_correct_logits, dim=-1)\n",
        "        one_hot_correct_target_ids = F.one_hot(correct_target_ids, num_classes=log_probs_correct_all.size(-1)).float()\n",
        "        selected_log_probs_correct = torch.einsum('bsv,bsv->bs', log_probs_correct_all, one_hot_correct_target_ids)\n",
        "        masked_log_probs_correct = selected_log_probs_correct * correct_target_mask.float()\n",
        "        sentence_log_probs_correct = masked_log_probs_correct.sum(dim=-1) # (batch_size,)\n",
        "\n",
        "        # For ungrammatical sentences\n",
        "        shifted_ungrammatical_logits = ungrammatical_logits[:, :-1, :].contiguous()\n",
        "        ungrammatical_target_ids = ungrammatical_input_ids[:, 1:]\n",
        "        ungrammatical_target_mask = ungrammatical_attention_mask[:, 1:]\n",
        "        log_probs_ungrammatical_all = torch.log_softmax(shifted_ungrammatical_logits, dim=-1)\n",
        "        one_hot_ungrammatical_target_ids = F.one_hot(ungrammatical_target_ids, num_classes=log_probs_ungrammatical_all.size(-1)).float()\n",
        "        selected_log_probs_ungrammatical = torch.einsum('bsv,bsv->bs', log_probs_ungrammatical_all, one_hot_ungrammatical_target_ids)\n",
        "        masked_log_probs_ungrammatical = selected_log_probs_ungrammatical * ungrammatical_target_mask.float()\n",
        "        sentence_log_probs_ungrammatical = masked_log_probs_ungrammatical.sum(dim=-1) # (batch_size,)\n",
        "\n",
        "        # Compare log probabilities within each pair (for Accuracy)\n",
        "        for i in range(sentence_log_probs_correct.shape[0]):\n",
        "            if sentence_log_probs_correct[i] > sentence_log_probs_ungrammatical[i]:\n",
        "                correct_predictions_bin += 1\n",
        "\n",
        "        # Calculate softmax probability over the two sentence log probabilities for each pair in the batch\n",
        "        # Stack log probabilities for softmax\n",
        "        stacked_log_probs = torch.stack([sentence_log_probs_ungrammatical, sentence_log_probs_correct], dim=-1) # (batch_size, 2)\n",
        "        softmax_probs = torch.softmax(stacked_log_probs, dim=-1) # (batch_size, 2)\n",
        "\n",
        "        # The metric value is the softmax probability corresponding to the correct sentence (index 1)\n",
        "        metric_values_batch = softmax_probs[:, 1] # (batch_size,)\n",
        "\n",
        "        group_metric_sum += metric_values_batch.sum().item()\n",
        "\n",
        "\n",
        "    # Calculate accuracy and average softmax probability metric for the current bin\n",
        "    accuracy_bin = (correct_predictions_bin / total_pairs_bin) * 100 if total_pairs_bin > 0 else 0\n",
        "    average_metric_bin = group_metric_sum / total_pairs_bin if total_pairs_bin > 0 else 0\n",
        "\n",
        "    new_length_group_accuracy[label] = accuracy_bin\n",
        "    new_length_group_metric[label] = average_metric_bin\n",
        "\n",
        "    print(f\"Length bin '{label}': {total_pairs_bin} pairs, Accuracy: {accuracy_bin:.2f}%, Average Softmax Probability over Sentence Log Probabilities: {average_metric_bin:.4f}\")\n",
        "\n",
        "# Print overall results by new length group\n",
        "print(\"\\nEvaluation Results by New Length Group:\")\n",
        "for label, accuracy in sorted(new_length_group_accuracy.items(), key=lambda item: sort_key(item[0])):\n",
        "    metric = new_length_group_metric[label]\n",
        "    print(f\"'{label}': Accuracy={accuracy:.2f}%, Average Softmax Probability over Sentence Log Probabilities: {metric:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh_xuuJMp_Gy",
        "outputId": "03d8b0b7-4e44-42a6-fc4f-f74a374eea5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating accuracy and calculating softmax probability over two sentence log probabilities for each length bin:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '0-9': 100%|██████████| 77/77 [00:15<00:00,  4.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '0-9': 308 pairs, Accuracy: 82.14%, Average Softmax Probability over Sentence Log Probabilities: 0.7908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '10-19': 100%|██████████| 273/273 [00:55<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '10-19': 1091 pairs, Accuracy: 83.32%, Average Softmax Probability over Sentence Log Probabilities: 0.8160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '20-29': 100%|██████████| 165/165 [00:33<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '20-29': 657 pairs, Accuracy: 86.00%, Average Softmax Probability over Sentence Log Probabilities: 0.8579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '30-39': 100%|██████████| 140/140 [00:28<00:00,  4.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '30-39': 560 pairs, Accuracy: 89.64%, Average Softmax Probability over Sentence Log Probabilities: 0.8826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '40-49': 100%|██████████| 121/121 [00:24<00:00,  4.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '40-49': 481 pairs, Accuracy: 91.27%, Average Softmax Probability over Sentence Log Probabilities: 0.9052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '50-59': 100%|██████████| 86/86 [00:17<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '50-59': 341 pairs, Accuracy: 91.79%, Average Softmax Probability over Sentence Log Probabilities: 0.9105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '60-69': 100%|██████████| 62/62 [00:12<00:00,  4.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '60-69': 248 pairs, Accuracy: 91.94%, Average Softmax Probability over Sentence Log Probabilities: 0.9165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '70-79': 100%|██████████| 44/44 [00:09<00:00,  4.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '70-79': 176 pairs, Accuracy: 94.32%, Average Softmax Probability over Sentence Log Probabilities: 0.9441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '80-89': 100%|██████████| 29/29 [00:05<00:00,  4.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '80-89': 114 pairs, Accuracy: 97.37%, Average Softmax Probability over Sentence Log Probabilities: 0.9600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '90-99': 100%|██████████| 15/15 [00:03<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '90-99': 59 pairs, Accuracy: 98.31%, Average Softmax Probability over Sentence Log Probabilities: 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '100-109': 100%|██████████| 11/11 [00:02<00:00,  5.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '100-109': 42 pairs, Accuracy: 95.24%, Average Softmax Probability over Sentence Log Probabilities: 0.9540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing bin '110+': 100%|██████████| 18/18 [00:03<00:00,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length bin '110+': 72 pairs, Accuracy: 100.00%, Average Softmax Probability over Sentence Log Probabilities: 0.9995\n",
            "\n",
            "Evaluation Results by New Length Group:\n",
            "'0-9': Accuracy=82.14%, Average Softmax Probability over Sentence Log Probabilities: 0.7908\n",
            "'10-19': Accuracy=83.32%, Average Softmax Probability over Sentence Log Probabilities: 0.8160\n",
            "'20-29': Accuracy=86.00%, Average Softmax Probability over Sentence Log Probabilities: 0.8579\n",
            "'30-39': Accuracy=89.64%, Average Softmax Probability over Sentence Log Probabilities: 0.8826\n",
            "'40-49': Accuracy=91.27%, Average Softmax Probability over Sentence Log Probabilities: 0.9052\n",
            "'50-59': Accuracy=91.79%, Average Softmax Probability over Sentence Log Probabilities: 0.9105\n",
            "'60-69': Accuracy=91.94%, Average Softmax Probability over Sentence Log Probabilities: 0.9165\n",
            "'70-79': Accuracy=94.32%, Average Softmax Probability over Sentence Log Probabilities: 0.9441\n",
            "'80-89': Accuracy=97.37%, Average Softmax Probability over Sentence Log Probabilities: 0.9600\n",
            "'90-99': Accuracy=98.31%, Average Softmax Probability over Sentence Log Probabilities: 0.9772\n",
            "'100-109': Accuracy=95.24%, Average Softmax Probability over Sentence Log Probabilities: 0.9540\n",
            "'110+': Accuracy=100.00%, Average Softmax Probability over Sentence Log Probabilities: 0.9995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}