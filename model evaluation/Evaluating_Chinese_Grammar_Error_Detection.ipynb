{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sJVkeWgbrnt"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ahLFQgoM3JCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd83574-ff4d-468d-877b-86886e3f9a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loaded 82980 sentences.\n",
            "[('因为庆祝会的日子是我母亲的生日。', 1, ['R']), ('是因为庆祝会的日子是我母亲的生日。', 0, ['R']), ('那下次见吧。', 1, ['R']), ('那下次见面吧。', 0, ['R']), ('我跟我朋友打算去法国玩儿。', 1, ['R']), ('我跟我朋唷友打算去法国玩儿。', 0, ['R']), ('所以我不能去。', 1, ['M']), ('所以我不能。', 0, ['M']), ('所以我写这一张卡送给你。', 1, ['R']), ('所以我写这一张卡送给你的。', 0, ['R'])]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Mount Google Drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/data_cged/training_data.jsonl'\n",
        "\n",
        "# Load the data\n",
        "def load_data(file_path):\n",
        "    sentences_data = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = [json.loads(line.strip()) for line in f]\n",
        "\n",
        "    for item in data:\n",
        "        # Remove non-pair entries (only grmmatical sentence)\n",
        "        if item[\"correct\"] != \"\" and item[\"error\"] != []:\n",
        "            grammatical = item[\"correct\"]\n",
        "            ungrammatical = item[\"text\"]\n",
        "            error_type = [dict[\"type\"] for dict in item[\"error\"]]\n",
        "            sentences_data.append((grammatical, 1, error_type))\n",
        "            sentences_data.append((ungrammatical, 0, error_type))\n",
        "\n",
        "    return sentences_data\n",
        "\n",
        "# Load the data\n",
        "sentences_data = load_data(file_path)\n",
        "\n",
        "# Inspect\n",
        "print(f\"Loaded {len(sentences_data)} sentences.\")\n",
        "print(sentences_data[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computing log probabilities"
      ],
      "metadata": {
        "id": "jnedDVp-PvQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check whether a GPU is available\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOcw8fblMbLl",
        "outputId": "e9f91871-835a-4024-af79-a1ccded7bdac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_logprobs(sentence, tokenizer, model):\n",
        "    # Tokenize the sentence\n",
        "    tokenized_input = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
        "    input_ids = tokenized_input.input_ids\n",
        "\n",
        "    # Disable gradient calculation because the model is not used for training\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "\n",
        "    # logits shape: (batch_size, seq_len, vocab_size)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Calculate log probabilities for each token (except first start token)\n",
        "    log_probs = []\n",
        "    for i in range(1, input_ids.shape[1]):\n",
        "        # Get logits for the previous position predicting the current token\n",
        "        current_logits = logits[0, i-1, :]\n",
        "        current_token_id = input_ids[0, i]\n",
        "\n",
        "        # Calculate log probability\n",
        "        # Apply log_softmax to convert logits to log probabilities\n",
        "        # Then select the log probability for the actual current token ID\n",
        "        log_prob = torch.log_softmax(current_logits, dim=-1)[current_token_id].item()\n",
        "        log_probs.append(log_prob)\n",
        "\n",
        "    # Total log probability (joint probability of all tokens)\n",
        "    total_log_prob = sum(log_probs)\n",
        "\n",
        "    return total_log_prob"
      ],
      "metadata": {
        "id": "nd4PfIIwnRMR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "2JlBR2LHnCpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGLM-564M"
      ],
      "metadata": {
        "id": "EZHhS9r_J7G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK7YxE2WBH7i",
        "outputId": "0a7eaa90-aceb-4eb4-e6f3-4b5370513470"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"facebook/xglm-564M\"\n",
        "\n",
        "tokenizer_xglm = AutoTokenizer.from_pretrained(model_name)\n",
        "model_xglm = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "model_xglm.eval()"
      ],
      "metadata": {
        "id": "APb-1-7iJbLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "# Append the original data along with the calculated log probability\n",
        "sentences_data_with_probs = []\n",
        "for sentence_data in tqdm.tqdm(sentences_data, desc=\"Processing\"):\n",
        "    sentence, label, error_type = sentence_data\n",
        "    total_log_prob = get_sentence_logprobs(sentence, tokenizer_xglm, model_xglm)\n",
        "    sentences_data_with_probs.append((sentence, label, error_type, total_log_prob))\n",
        "\n",
        "# Inspect\n",
        "for data in sentences_data_with_probs[:2]:\n",
        "    print(f\"\\nSentence: {data[0]}\")\n",
        "    print(f\"Label: {data[1]}, Error Type: {data[2]}\")\n",
        "    print(f\"Total Log Probability: {data[3]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMl52POzBAiT",
        "outputId": "62644b60-39e0-4c5a-c25b-b215debd7524"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 82980/82980 [37:28<00:00, 36.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: 因为庆祝会的日子是我母亲的生日。\n",
            "Label: 1, Error Type: ['R']\n",
            "Total Log Probability: -50.02\n",
            "\n",
            "Sentence: 是因为庆祝会的日子是我母亲的生日。\n",
            "Label: 0, Error Type: ['R']\n",
            "Total Log Probability: -55.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "xNHyrhFQyrjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(sentences_data_with_probs):\n",
        "    correct_by_error_type = {}\n",
        "    total_by_error_type = {}\n",
        "    overall_correct_pairs = 0\n",
        "    total_pairs = 0\n",
        "\n",
        "    # Assuming correct and ungrammatical sentences are paired consecutively\n",
        "    for i in range(0, len(sentences_data_with_probs), 2):\n",
        "        total_pairs += 1\n",
        "        prob_correct = sentences_data_with_probs[i][3]\n",
        "        prob_ungrammatical = sentences_data_with_probs[i+1][3]\n",
        "\n",
        "        # Calculate overall correct count\n",
        "        if prob_correct > prob_ungrammatical:\n",
        "            overall_correct_pairs += 1\n",
        "\n",
        "\n",
        "        # Handle cases with multiple error types by sorting and converting to a tuple\n",
        "        error_types_list =  sentences_data_with_probs[i+1][2]\n",
        "        error_type_key = tuple(sorted(error_types_list)) if isinstance(error_types_list, list) else error_types_list\n",
        "\n",
        "        # Initialize dictionaries of error type combinations\n",
        "        if error_type_key not in total_by_error_type:\n",
        "            total_by_error_type[error_type_key] = 0\n",
        "            correct_by_error_type[error_type_key] = 0\n",
        "\n",
        "        total_by_error_type[error_type_key] += 1\n",
        "\n",
        "        # Calculate correct count by error type\n",
        "        if prob_correct > prob_ungrammatical:\n",
        "            correct_by_error_type[error_type_key] += 1\n",
        "\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    overall_accuracy = (overall_correct_pairs / total_pairs) * 100 if total_pairs > 0 else 0\n",
        "\n",
        "\n",
        "    # Calculate accuracy for each error type\n",
        "    accuracy_by_error_type = []\n",
        "\n",
        "    # ONLY consider combinations that consist of a single error type\n",
        "    for error_type_key in sorted(total_by_error_type.keys()):\n",
        "        if len(error_type_key) == 1:\n",
        "            total = total_by_error_type[error_type_key]\n",
        "            correct = correct_by_error_type[error_type_key]\n",
        "            type_accuracy = (correct / total) * 100 if total > 0 else 0\n",
        "\n",
        "            display_key = list(error_type_key) if isinstance(error_type_key, tuple) else error_type_key\n",
        "            accuracy_by_error_type.append({'Error Type': display_key, 'Accuracy (%)': type_accuracy, 'Correct': correct, 'Total': total})\n",
        "\n",
        "    return overall_accuracy, overall_correct_pairs, total_pairs, accuracy_by_error_type"
      ],
      "metadata": {
        "id": "bDI_NJSbsr7f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_accuracy, overall_correct_pairs, total_pairs, accuracy_by_error_type = evaluate_model(sentences_data_with_probs)\n",
        "\n",
        "print(f\"Overall Accuracy (XGLM-564M): {overall_accuracy:.2f}% ({overall_correct_pairs}/{total_pairs})\")\n",
        "\n",
        "print(\"\\nAccuracy by Error Type:\")\n",
        "# Sort by accuracy low to high before printing\n",
        "sorted_accuracy_by_error_type = sorted(accuracy_by_error_type, key=lambda x: x['Accuracy (%)'])\n",
        "\n",
        "for item in sorted_accuracy_by_error_type:\n",
        "    print(f\"  Error Type: {item['Error Type']}: {item['Accuracy (%)']:.2f}% ({item['Correct']}/{item['Total']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4i3HlugMdxt",
        "outputId": "84205f1e-400a-4afd-f293-a5c5c54185ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy (XGLM-564M): 81.07% (33636/41490)\n",
            "\n",
            "Accuracy by Error Type:\n",
            "  Error Type: ['M']: 54.05% (4241/7847)\n",
            "  Error Type: ['W']: 81.25% (2097/2581)\n",
            "  Error Type: ['S']: 83.25% (5184/6227)\n",
            "  Error Type: ['R']: 96.11% (5613/5840)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLOOM-560M"
      ],
      "metadata": {
        "id": "7tvLShCpYqXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"bigscience/bloom-560m\"\n",
        "\n",
        "tokenizer_bloom = AutoTokenizer.from_pretrained(model_name)\n",
        "model_bloom = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "model_bloom.eval()"
      ],
      "metadata": {
        "id": "p9-Vx7CnYmfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the original data along with the calculated log probability\n",
        "sentences_data_with_probs = []\n",
        "for sentence_data in tqdm.tqdm(sentences_data, desc=\"Processing\"):\n",
        "    sentence, label, error_type = sentence_data\n",
        "    total_log_prob = get_sentence_logprobs(sentence, tokenizer_bloom, model_bloom)\n",
        "    sentences_data_with_probs.append((sentence, label, error_type, total_log_prob))\n",
        "\n",
        "# Inspect\n",
        "for data in sentences_data_with_probs[:2]:\n",
        "    print(f\"\\nSentence: {data[0]}\")\n",
        "    print(f\"Label: {data[1]}, Error Type: {data[2]}\")\n",
        "    print(f\"Total Log Probability: {data[3]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYoayFSIY_Bu",
        "outputId": "9c5411d7-d018-42fa-8a7e-29ce25b3b72c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 82980/82980 [35:39<00:00, 38.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: 因为庆祝会的日子是我母亲的生日。\n",
            "Label: 1, Error Type: ['R']\n",
            "Total Log Probability: -44.71\n",
            "\n",
            "Sentence: 是因为庆祝会的日子是我母亲的生日。\n",
            "Label: 0, Error Type: ['R']\n",
            "Total Log Probability: -44.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_accuracy, overall_correct_pairs, total_pairs, accuracy_by_error_type = evaluate_model(sentences_data_with_probs)\n",
        "\n",
        "print(f\"Overall Accuracy (BLOOM-560M): {overall_accuracy:.2f}% ({overall_correct_pairs}/{total_pairs})\")\n",
        "\n",
        "print(\"\\nAccuracy by Error Type:\")\n",
        "# Sort by accuracy low to high before printing\n",
        "sorted_accuracy_by_error_type = sorted(accuracy_by_error_type, key=lambda x: x['Accuracy (%)'])\n",
        "\n",
        "for item in sorted_accuracy_by_error_type:\n",
        "    print(f\"  Error Type: {item['Error Type']}: {item['Accuracy (%)']:.2f}% ({item['Correct']}/{item['Total']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acaa62f-fead-419a-c188-2c43dc990b09",
        "id": "Hkn3sqm9ZZhJ"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy (BLOOM-560M): 82.37% (34177/41490)\n",
            "\n",
            "Accuracy by Error Type:\n",
            "  Error Type: ['M']: 55.86% (4383/7847)\n",
            "  Error Type: ['W']: 80.90% (2088/2581)\n",
            "  Error Type: ['S']: 84.37% (5254/6227)\n",
            "  Error Type: ['R']: 95.22% (5561/5840)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qwen3-0.6B"
      ],
      "metadata": {
        "id": "nyt09gytZm5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"Qwen/Qwen3-0.6B\"\n",
        "\n",
        "tokenizer_qwen = AutoTokenizer.from_pretrained(model_name)\n",
        "model_qwen = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "model_qwen.eval()"
      ],
      "metadata": {
        "id": "7h04A6D_ZpGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the original data along with the calculated log probability\n",
        "sentences_data_with_probs = []\n",
        "for sentence_data in tqdm.tqdm(sentences_data, desc=\"Processing\"):\n",
        "    sentence, label, error_type = sentence_data\n",
        "    total_log_prob = get_sentence_logprobs(sentence, tokenizer_qwen, model_qwen)\n",
        "    sentences_data_with_probs.append((sentence, label, error_type, total_log_prob))\n",
        "\n",
        "# Inspect\n",
        "for data in sentences_data_with_probs[:2]:\n",
        "    print(f\"\\nSentence: {data[0]}\")\n",
        "    print(f\"Label: {data[1]}, Error Type: {data[2]}\")\n",
        "    print(f\"Total Log Probability: {data[3]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23eec3a8-34fe-452e-eab4-f7b8569ecbab",
        "id": "w2-2MsUTZyNx"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 82980/82980 [1:00:46<00:00, 22.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: 因为庆祝会的日子是我母亲的生日。\n",
            "Label: 1, Error Type: ['R']\n",
            "Total Log Probability: -43.79\n",
            "\n",
            "Sentence: 是因为庆祝会的日子是我母亲的生日。\n",
            "Label: 0, Error Type: ['R']\n",
            "Total Log Probability: -44.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_accuracy, overall_correct_pairs, total_pairs, accuracy_by_error_type = evaluate_model(sentences_data_with_probs)\n",
        "\n",
        "print(f\"Overall Accuracy (BLOOM-560M): {overall_accuracy:.2f}% ({overall_correct_pairs}/{total_pairs})\")\n",
        "\n",
        "print(\"\\nAccuracy by Error Type:\")\n",
        "# Sort by accuracy low to high before printing\n",
        "sorted_accuracy_by_error_type = sorted(accuracy_by_error_type, key=lambda x: x['Accuracy (%)'])\n",
        "\n",
        "for item in sorted_accuracy_by_error_type:\n",
        "    print(f\"  Error Type: {item['Error Type']}: {item['Accuracy (%)']:.2f}% ({item['Correct']}/{item['Total']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8bb3e6a-139a-4d54-b3a1-32b770cdf5b1",
        "id": "EigyyZMzZ1Lp"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy (BLOOM-560M): 79.07% (32807/41490)\n",
            "\n",
            "Accuracy by Error Type:\n",
            "  Error Type: ['M']: 51.89% (4072/7847)\n",
            "  Error Type: ['W']: 72.03% (1859/2581)\n",
            "  Error Type: ['S']: 81.87% (5098/6227)\n",
            "  Error Type: ['R']: 93.41% (5455/5840)\n"
          ]
        }
      ]
    }
  ]
}